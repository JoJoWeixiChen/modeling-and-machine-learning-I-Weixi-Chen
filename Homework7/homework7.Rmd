---
title: "Homework7"
author: "Weixi Chen"
date: "2022/4/11"
output: github_document
---

```{r}
library(rgl)
library(keras)
library(nnet)
library(dplyr)
library(ElemStatLearn)
```

```{r}
## load binary classification example data
data('mixture.example')
dat <- mixture.example
```


### problem2

```{r}
model <- keras_model_sequential()
model %>%
  layer_flatten(input_shape = c(2,1)) %>%
  layer_dense(units = 10, activation = 'relu') %>%
  layer_dense(units = 2, activation = 'softmax')
```

```{r}
model %>% compile(
  optimizer = 'adam',
  loss = 'sparse_categorical_crossentropy',
  metrics = c('accuracy')
)
```

```{r}
fit1 <- model %>% fit(dat$x, dat$y, epochs = 5, verbose = 2)
```

### problem3

```{r}
plot_mixture_data <- function(dat=mixture.example, showtruth=FALSE) {
  ## create 3D graphic, rotate to view 2D x1/x2 projection
  par3d(FOV=1,userMatrix=diag(4))
  plot3d(dat$xnew[,1], dat$xnew[,2], dat$prob, type="n",
         xlab="x1", ylab="x2", zlab="",
         axes=FALSE, box=TRUE, aspect=1)
  ## plot points and bounding box
  x1r <- range(dat$px1)
  x2r <- range(dat$px2)
  pts <- plot3d(dat$x[,1], dat$x[,2], 1,
                type="p", radius=0.5, add=TRUE,
                col=ifelse(dat$y, "orange", "blue"))
  lns <- lines3d(x1r[c(1,2,2,1,1)], x2r[c(1,1,2,2,1)], 1)
  
  if(showtruth) {
    ## draw Bayes (True) classification boundary
    probm <- matrix(dat$prob, length(dat$px1), length(dat$px2))
    cls <- contourLines(dat$px1, dat$px2, probm, levels=0.5)
    pls <- lapply(cls, function(p) 
      lines3d(p$x, p$y, z=1, col='purple', lwd=3))
    ## plot marginal probability surface and decision plane
    sfc <- surface3d(dat$px1, dat$px2, dat$prob, alpha=1.0,
      color="gray", specular="gray")
    qds <- quads3d(x1r[c(1,2,2,1)], x2r[c(1,1,2,2)], 0.5, alpha=0.4,
      color="gray", lit=FALSE)
  }
}
```

```{r}
plot_nnet_predictions <- function(fit, dat=mixture.example) {
  
  ## create figure
  plot_mixture_data()

  ## compute predictions from nnet
  preds <- predict(fit, dat$xnew, type="class")
  probs <- predict(fit, dat$xnew, type="raw")[,1]
  probm <- matrix(probs, length(dat$px1), length(dat$px2))
  cls <- contourLines(dat$px1, dat$px2, probm, levels=0.5)

  ## plot classification boundary
  pls <- lapply(cls, function(p) 
    lines3d(p$x, p$y, z=1, col='purple', lwd=2))
  
  ## plot probability surface and decision plane
  sfc <- surface3d(dat$px1, dat$px2, probs, alpha=1.0,
                   color="gray", specular="gray")
  qds <- quads3d(x1r[c(1,2,2,1)], x2r[c(1,1,2,2)], 0.5, alpha=0.4,
                 color="gray", lit=FALSE)
}
```

```{r}
fit2 <- nnet(dat$x, dat$y, size = 10, entropy = TRUE, decay = 0)
```

```{r}
plot_mixture_data(showtruth = TRUE)
plot_nnet_predictions(fit1)
```

```{r}
plot_mixture_data(showtruth = TRUE)
plot_nnet_predictions(fit2)
```

From the figures above, we can see that the predictions are similar using the 'nnet' function versus the Keras model.


